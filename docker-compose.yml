# docker-compose.yml
version: '3.8'

services:
  spark-app:
    # Build the image using the Dockerfile in the current directory (.)
    build: .
    container_name: earthquake_pipeline_app
    # Define the working directory inside the container
    working_dir: /app
    # Mount the local ./data directory to /app/data inside the container
    # This allows data generated inside the container (raw/processed)
    # to persist on your host machine and vice-versa.
    volumes:
      - ./data:/app/data
    # Keep the container running in the background so we can execute commands in it
    # Alternatively, define specific commands below
    # command: tail -f /dev/null

    # Example of overriding the command to run ingestion directly:
    # command: ["python", "src/ingestion.py"]